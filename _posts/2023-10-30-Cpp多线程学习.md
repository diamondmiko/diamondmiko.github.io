---
layout: article
title: "Cpp多线程学习"
---

# 多线程

```C++
#include <iostream>
#include <thread>
using namespace std;
void proc(int &a){
    std::cout << "子线程，输入：" << a << std::endl;
    std::cout << "子线程id：" << std::this_thread::get_id() << std::endl;
}
int main()
{
    std::cout << "我是主线程" << std::endl;
    int a = 9;
    thread th2(proc,ref(a));
    cout << "主线程中显示子线程id为" << th2.get_id() << endl;
    th2.join();
    return 0;
}
```

## 互斥锁

互斥量是为了解决数据共享过程中可能存在的访问冲突问题。这里互斥量保证使用过程不被打断。

## 死锁

多线程编程时要考虑多个线程同时访问共享资源所造成的问题。因此可以通过加锁解锁来保证同一时刻只有一个线程能够访问共享资源；使用锁的时候要注意，不能出现死锁的状况；

死锁就是多个线程争夺共享资源导致每个线程都熊取得子集所需的全部资源，从而线程无法向下执行。

==产生死锁的四个必要条件==（面试）：
1.互斥（资源同一时刻只能被一个进程使用）
2.请求并保持（进程在请资源时，不释放自己已经占有的资源）
3.不剥夺（进程已经获得的资源，在进程使用完前，不能强制剥夺）
4.循环等待（进程间形成环状的资源循环等待关系）

死锁预防：

破坏死锁产生的四个条件（完全杜绝死锁）

死锁避免：

对分配资源做安全性检查，确保不会产生循环等待（银行家算法）

死锁检测：

允许死锁产生，但提供检测方法

死锁解除：

已经产生了死锁，强制剥夺资源或者撤销进程。

## 临界区、信号量、互斥锁

都是用于进行进程的同步与互斥；
==临界区==速度最快，但只能作用于同一进程下不同线程，不能作用于不同进程；临界区可确保某一代码段同一时刻只能被一个线程执行；

`EnterCriticalSection()` 进入临界区
`LeaveCriticalSection()` 离开临界区

信号量多个线程同一时刻访问共享资源，进行线程的计数，确保同时访问资源的线程数目不超过上限，当访问数超过上线后，不发出信号量。

互斥锁：支持不同进程间的同步与互斥（互斥就是保证资源同一时刻只能被一个进程使用；互斥是为了保证数据的一致性，如果A线程在执行计算式A的时候，某个量被B线程改掉了，这可能会出现问题，于是要求资源互斥，我在用它你就不能用，等我用完了你再用，我们彼此互不干扰。）

读写锁：
`shared_mutex`读写锁把共享资源的访问者划分为读者和写者，多个读线程能同时读取共享资源，但只有一个写线程能同时读取共享资源。
`shared_mutex`通过`lock_shared`,`unlock_shared`进行读者的锁定与解锁；通过lock，unlock进行写者的锁定与解锁。

```c++
#include<iostream>
#include<thread>
#include<mutex>
using namespace std;
mutex m;//实例化m对象，不要理解为定义变量
void proc1(int a)
{
    m.lock();
    cout << "proc1函数正在改写a" << endl;
    cout << "原始a为" << a << endl;
    cout << "现在a为" << a + 2 << endl;
    m.unlock();
}

void proc2(int a)
{
    m.lock();
    cout << "proc2函数正在改写a" << endl;
    cout << "原始a为" << a << endl;
    cout << "现在a为" << a + 1 << endl;
    m.unlock();
}
int main()
{
    int a = 0;
    thread t1(proc1, a);
    thread t2(proc2, a);
    t1.join();
    t2.join();
    return 0;
}
```

```bash
#加锁后的结果
PS D:\code\Cplusplus_test> .\test.exe
proc1函数正在改写a
原始a为0
现在a为2
proc2函数正在改写a
原始a为0
现在a为1
#未加锁的结果
proc1函数正在改写aproc2函数正在改写a
原始a为
原始a为0
现在a为2
0
现在a为1
```

## lock_guard

声明一个局部的std::lock_guard对象，在其构造函数中进行加锁，在其析构函数中进行解锁。最终的结果就是：创建即加锁，作用域结束自动解锁。从而使用std::lock_guard()就可以替代lock()与unlock()。

通过设定作用域，使得std::lock_guard在合适的地方被析构（在互斥量锁定到互斥量解锁之间的代码叫做临界区（需要互斥访问共享资源的那段代码称为临界区），临界区范围应该尽可能的小，即lock互斥量后应该尽早unlock），通过使用{}来调整作用域范围，可使得互斥量m在合适的地方被解锁

```C++
#include<iostream>
#include<thread>
#include<mutex>
using namespace std;
mutex m;//实例化m对象，不要理解为定义变量
void proc1(int a)
{
    lock_guard<mutex> g1(m);//用此语句替换了m.lock()；lock_guard传入一个参数时，该参数为互斥量，此时调用了lock_guard的构造函数，申请锁定m
    cout << "proc1函数正在改写a" << endl;
    cout << "原始a为" << a << endl;
    cout << "现在a为" << a + 2 << endl;
}//此时不需要写m.unlock(),g1出了作用域被释放，自动调用析构函数，于是m被解锁

void proc2(int a)
{
    {
        lock_guard<mutex> g2(m);
        cout << "proc2函数正在改写a" << endl;
        cout << "原始a为" << a << endl;
        cout << "现在a为" << a + 1 << endl;
    }//通过使用{}来调整作用域范围，可使得m在合适的地方被解锁
    cout << "作用域外的内容3" << endl;
    cout << "作用域外的内容4" << endl;
    cout << "作用域外的内容5" << endl;
}
int main()
{
    int a = 0;
    thread t1(proc1, a);
    thread t2(proc2, a);
    t1.join();
    t2.join();
    return 0;
}
```

## Unique_lock

支持参数：adopt_lock,还可以是try_to_lock与defer_lock;

## 异步线程\<future>

async与future：
std::async是一个函数模板，用来启动一个异步任务，它返回一个std::future类模板对象，future对象起到了占位的作用（记住这点就可以了），占位是什么意思？就是说该变量现在无值，但将来会有值（好比你挤公交瞧见空了个座位，刚准备坐下去就被旁边的小伙给拦住了：“这个座位有人了”，你反驳道：”这不是空着吗？“，小伙：”等会人就来了“）,刚实例化的future是没有储存值的，但在调用std::future对象的get()成员函数时，主线程会被阻塞直到异步线程执行结束，并把返回结果传递给std::future，即通过FutureObject.get()获取函数返回值。

std::shared_future() 具备数据所有权。

## 原子类型atomic

```cpp
//原子类型的简单使用
std::atomic<bool> b(true);
b=false;
```

## 代码实例

### 生产者消费者问题

生产者-消费者模型是经典的多线程并发协作模型。

生产者用于生产数据，生产一个就往共享数据区存一个，如果共享数据区已满的话，生产者就暂停生产，等待消费者的通知后再启动。

消费者用于消费数据，一个一个的从共享数据区取，如果共享数据区为空的话，消费者就暂停取数据，等待生产者的通知后再启动。

生产者与消费者不能直接交互,它们之间所共享的数据使用队列结构来实现;

```cpp
#include<iostream>
#include<thread>
#include<mutex>
#include<queue>
#include<condition_variable>


using namespace std;

//缓冲区存储的数据类型 
struct CacheData
{
	//商品id 
	int id;
	//商品属性 
	string data;
};

queue<CacheData> Q;
//缓冲区最大空间 
const int MAX_CACHEDATA_LENGTH = 10;
//互斥量，生产者之间，消费者之间，生产者和消费者之间，同时都只能一个线程访问缓冲区 
mutex m;
condition_variable condConsumer;
condition_variable condProducer;
//全局商品id 
int ID = 1;

//消费者动作 
void ConsumerActor()
{
	unique_lock<mutex> lockerConsumer(m);
	cout << "[" << this_thread::get_id() << "] 获取了锁" << endl; 
	while (Q.empty())
	{
		cout <<  "因为队列为空，所以消费者Sleep" << endl; 
		cout << "[" << this_thread::get_id() << "] 不再持有锁" << endl;
		//队列空， 消费者停止，等待生产者唤醒 
		condConsumer.wait(lockerConsumer);
		cout << "[" << this_thread::get_id() << "] Weak, 重新获取了锁" << endl; 
	}
	cout << "[" << this_thread::get_id() << "] "; 
	CacheData temp = Q.front();
	cout << "- ID:" << temp.id << " Data:" << temp.data << endl;
	Q.pop(); 
	condProducer.notify_one();
	cout << "[" << this_thread::get_id() << "] 释放了锁" << endl; 
}

//生产者动作 
void ProducerActor()
{
	unique_lock<mutex> lockerProducer(m);
	cout << "[" << this_thread::get_id() << "] 获取了锁" << endl; 
	while (Q.size() > MAX_CACHEDATA_LENGTH)
	{
		cout <<  "因为队列为满，所以生产者Sleep" << endl; 
		cout << "[" << this_thread::get_id() << "] 不再持有锁" << endl; 
		//对列慢，生产者停止，等待消费者唤醒 
		condProducer.wait(lockerProducer);
		cout << "[" << this_thread::get_id() << "] Weak, 重新获取了锁" << endl; 
	}
	cout << "[" << this_thread::get_id() << "] "; 
	CacheData temp;
	temp.id = ID++;
	temp.data = "*****";
	cout << "+ ID:" << temp.id << " Data:" << temp.data << endl; 
	Q.push(temp);
	condConsumer.notify_one();
	cout << "[" << this_thread::get_id() << "] 释放了锁" << endl; 
}

//消费者 
void ConsumerTask()
{
	while(1)
	{
		ConsumerActor();
	}	
}

//生产者 
void ProducerTask()
{
	while(1)
	{
		ProducerActor();
	}	
}

//管理线程的函数 
void Dispatch(int ConsumerNum, int ProducerNum)
{
	vector<thread> thsC;
	for (int i = 0; i < ConsumerNum; ++i)
	{
		thsC.push_back(thread(ConsumerTask));
	}
	
	vector<thread> thsP;
	for (int j = 0; j < ProducerNum; ++j)
	{
		thsP.push_back(thread(ProducerTask));
	}
	
	for (int i = 0; i < ConsumerNum; ++i)
	{
		if (thsC[i].joinable())
		{
			thsC[i].join();
		}
	}
	
	for (int j = 0; j < ProducerNum; ++j)
	{
		if (thsP[j].joinable())
		{
			thsP[j].join();
		}
	}
}

int main()
{
	//一个消费者线程，5个生产者线程，则生产者经常要等待消费者 
	Dispatch(1,5);
	return 0; 
}
```

## 线程池

不采用线程池时：

创建线程 -> 由该线程执行任务 -> 任务执行完毕后销毁线程。即使需要使用到大量线程，每个线程都要按照这个流程来创建、执行与销毁。

虽然创建与销毁线程消耗的时间 远小于 线程执行的时间，但是对于需要频繁创建大量线程的任务，创建与销毁线程 所占用的时间与CPU资源也会有很大占比。

为了减少创建与销毁线程所带来的时间消耗与资源消耗，因此采用线程池的策略：

程序启动后，预先创建一定数量的线程放入空闲队列中，这些线程都是处于阻塞状态，基本不消耗CPU，只占用较小的内存空间。

接收到任务后，任务被挂在任务队列，线程池选择一个空闲线程来执行此任务。

任务执行完毕后，不销毁线程，线程继续保持在池中等待下一次的任务。

线程池所解决的问题：

(1) 需要频繁创建与销毁大量线程的情况下，由于线程预先就创建好了，接到任务就能马上从线程池中调用线程来处理任务，减少了创建与销毁线程带来的时间开销和CPU资源占用。

(2) 需要并发的任务很多时候，无法为每个任务指定一个线程（线程不够分），使用线程池可以将提交的任务挂在任务队列上，等到池中有空闲线程时就可以为该任务指定线程。
